# ======================================
# ë°ì´í„° ë“œë¦¬í”„íŠ¸ ê°ì§€ (PSI ê¸°ë°˜) 
# ======================================
import pandas as pd
import numpy as np
import s3fs
from datetime import datetime

print("=" * 70)
print("ğŸ“Š ë°ì´í„° ë“œë¦¬í”„íŠ¸ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
print("=" * 70)

# --- MinIO ì—°ê²° ì„¤ì • ---
fs = s3fs.S3FileSystem(
    key="minioadmin",
    secret="minioadmin",
    client_kwargs={"endpoint_url": "http://localhost:9900"}
)

# --- 1ï¸âƒ£ ê¸°ì¤€(reference) ë°ì´í„° ë¡œë“œ ---
print("\n[1/5] ê¸°ì¤€ ë°ì´í„° ë¡œë”©...")
reference_path = "s3://model-logs/session-purchase/reference_data.csv"

try:
    with fs.open(reference_path, "rb") as f:
        ref_df = pd.read_csv(f)
    print(f"   âœ… ê¸°ì¤€ ë°ì´í„°: {ref_df.shape[0]}í–‰ Ã— {ref_df.shape[1]}ì—´")
except FileNotFoundError:
    print(f"   âŒ ê¸°ì¤€ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {reference_path}")
    print(f"   ğŸ’¡ ë¨¼ì € 'python ml-pipeline/monitoring/save_reference.py'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”")
    exit(1)
except Exception as e:
    print(f"   âŒ ê¸°ì¤€ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    exit(1)

# --- 2ï¸âƒ£ ìµœê·¼ ì˜ˆì¸¡ ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸° ---
print("\n[2/5] ìµœê·¼ ì˜ˆì¸¡ ë¡œê·¸ ë¡œë”©...")
log_path = "s3://model-logs/session-purchase/inference-logs.csv"

try:
    with fs.open(log_path, "rb") as f:
        cur_df = pd.read_csv(f)
    print(f"   âœ… ì˜ˆì¸¡ ë¡œê·¸: {cur_df.shape[0]}í–‰ Ã— {cur_df.shape[1]}ì—´")
    print(f"   ğŸ“… ë¡œê·¸ ê¸°ê°„: {cur_df['timestamp'].min()} ~ {cur_df['timestamp'].max()}")
except FileNotFoundError:
    print(f"   âŒ ì˜ˆì¸¡ ë¡œê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {log_path}")
    print(f"   ğŸ’¡ ë¨¼ì € ì˜ˆì¸¡ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ë¡œê·¸ë¥¼ ìƒì„±í•˜ì„¸ìš”")
    exit(1)
except Exception as e:
    print(f"   âŒ ì˜ˆì¸¡ ë¡œê·¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    exit(1)

# --- 3ï¸âƒ£ í”¼ì²˜ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ (ê³µí†µ ì»¬ëŸ¼ ì°¾ê¸°) ---
print("\n[3/5] í”¼ì²˜ ì¶”ì¶œ ë° ì •ë ¬...")

# ì˜ˆì¸¡ ê²°ê³¼ ì»¬ëŸ¼ ì œì™¸
exclude_cols = ['probability', 'prediction', 'threshold', 'model_version', 
                'used_features', 'timestamp', 'has_transaction']
feature_cols = [col for col in ref_df.columns if col not in exclude_cols]

# í˜„ì¬ ë¡œê·¸ì—ì„œë„ ë™ì¼í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
cur_feature_cols = [col for col in cur_df.columns if col in feature_cols]

if not cur_feature_cols:
    print(f"   âŒ ê³µí†µ í”¼ì²˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    print(f"   ê¸°ì¤€ ë°ì´í„° ì»¬ëŸ¼: {ref_df.columns.tolist()[:5]}...")
    print(f"   ì˜ˆì¸¡ ë¡œê·¸ ì»¬ëŸ¼: {cur_df.columns.tolist()[:5]}...")
    exit(1)

ref = ref_df[cur_feature_cols]
cur = cur_df[cur_feature_cols]

print(f"   âœ… ë¶„ì„ ëŒ€ìƒ í”¼ì²˜: {len(cur_feature_cols)}ê°œ")
print(f"   ğŸ“‹ í”¼ì²˜ ëª©ë¡: {cur_feature_cols[:5]}{'...' if len(cur_feature_cols) > 5 else ''}")

# --- 4ï¸âƒ£ PSI ê³„ì‚° í•¨ìˆ˜ ---
def calculate_psi(expected, actual, buckets=10):
    """
    Population Stability Index (PSI) ê³„ì‚°
    - PSI < 0.1: ì•ˆì •ì  (Stable)
    - 0.1 â‰¤ PSI < 0.25: ì¤‘ê°„ ë“œë¦¬í”„íŠ¸ (Moderate Drift)
    - PSI â‰¥ 0.25: ì‹¬ê°í•œ ë“œë¦¬í”„íŠ¸ (Significant Drift)
    """
    # ê²°ì¸¡ì¹˜ ì œê±°
    expected = expected[~np.isnan(expected)]
    actual = actual[~np.isnan(actual)]
    
    if len(expected) == 0 or len(actual) == 0:
        return np.nan
    
    # êµ¬ê°„ ìƒì„± (expected ê¸°ì¤€)
    breakpoints = np.percentile(expected, np.linspace(0, 100, buckets + 1))
    breakpoints = np.unique(breakpoints)  # ì¤‘ë³µ ì œê±°
    
    if len(breakpoints) < 2:
        return np.nan
    
    # ê° êµ¬ê°„ì˜ ë¹„ìœ¨ ê³„ì‚°
    expected_percents = np.histogram(expected, bins=breakpoints)[0] / len(expected)
    actual_percents = np.histogram(actual, bins=breakpoints)[0] / len(actual)
    
    # PSI ê³„ì‚° (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
    expected_percents = np.where(expected_percents == 0, 1e-6, expected_percents)
    actual_percents = np.where(actual_percents == 0, 1e-6, actual_percents)
    
    psi_value = np.sum((actual_percents - expected_percents) * 
                       np.log(actual_percents / expected_percents))
    
    return psi_value

# --- 5ï¸âƒ£ ì „ì²´ í”¼ì²˜ì— ëŒ€í•´ PSI ê³„ì‚° ---
print("\n[4/5] PSI ê³„ì‚° ì¤‘...")
psi_results = {}

for col in cur_feature_cols:
    try:
        psi = calculate_psi(ref[col].values, cur[col].values)
        psi_results[col] = psi
    except Exception as e:
        print(f"   âš ï¸ {col} ê³„ì‚° ì‹¤íŒ¨: {e}")
        psi_results[col] = np.nan

psi_df = pd.DataFrame(list(psi_results.items()), columns=["feature", "psi"])
psi_df = psi_df.sort_values("psi", ascending=False)

# ì•ˆì •ì„± ë¶„ë¥˜
psi_df["stability"] = pd.cut(
    psi_df["psi"],
    bins=[-np.inf, 0.1, 0.25, np.inf],
    labels=["âœ… Stable", "âš ï¸ Moderate Drift", "ğŸš¨ Significant Drift"]
)

print(f"   âœ… PSI ê³„ì‚° ì™„ë£Œ")

# --- 6ï¸âƒ£ ê²°ê³¼ ì¶œë ¥ ---
print("\n" + "=" * 70)
print("ğŸ“Š ë°ì´í„° ë“œë¦¬í”„íŠ¸ ê°ì§€ ê²°ê³¼")
print("=" * 70)
print(psi_df.to_string(index=False))

# ìš”ì•½ í†µê³„
print("\n" + "=" * 70)
print("ğŸ“ˆ ìš”ì•½ í†µê³„")
print("=" * 70)
stability_counts = psi_df["stability"].value_counts()
for status, count in stability_counts.items():
    print(f"   {status}: {count}ê°œ í”¼ì²˜")

# ê²½ê³ ê°€ í•„ìš”í•œ í”¼ì²˜
drifted = psi_df[psi_df["psi"] >= 0.25]
if len(drifted) > 0:
    print("\nğŸš¨ ì£¼ì˜ê°€ í•„ìš”í•œ í”¼ì²˜ (PSI â‰¥ 0.25):")
    for _, row in drifted.iterrows():
        print(f"   - {row['feature']}: PSI = {row['psi']:.4f}")
else:
    print("\nâœ… ëª¨ë“  í”¼ì²˜ê°€ ì•ˆì •ì ì…ë‹ˆë‹¤!")

# --- 7ï¸âƒ£ MinIOì— ì—…ë¡œë“œ ---
print("\n[5/5] ê²°ê³¼ ì €ì¥ ì¤‘...")
result_path = "s3://model-logs/session-purchase/psi_report.csv"

try:
    psi_df.to_csv("psi_report.csv", index=False)
    fs.put("psi_report.csv", result_path)
    print(f"   âœ… PSI ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ â†’ {result_path}")
except Exception as e:
    print(f"   âš ï¸ MinIO ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
    print(f"   ğŸ’¾ ë¡œì»¬ íŒŒì¼ë¡œ ì €ì¥ë¨: psi_report.csv")

print("\n" + "=" * 70)
print("âœ… ë°ì´í„° ë“œë¦¬í”„íŠ¸ ëª¨ë‹ˆí„°ë§ ì™„ë£Œ!")
print("=" * 70)