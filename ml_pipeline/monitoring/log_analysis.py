import os
import pandas as pd
import s3fs
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import matplotlib.font_manager as fm

plt.rcParams['font.family'] = 'NanumGothic'  
plt.rcParams['axes.unicode_minus'] = False

# --------------------------------------------------
# 1ï¸âƒ£ MinIO ì—°ê²° ì„¤ì •
# --------------------------------------------------
MINIO_ENDPOINTS = [
    "http://host.docker.internal:9900",  # Docker/WSL í™˜ê²½
    "http://localhost:9900",             # ë¡œì»¬ ì§ì ‘ ì‹¤í–‰
    "http://172.28.159.42:9900",         # ë‚´ë¶€ ë„¤íŠ¸ì›Œí¬ IP (FastAPIì™€ ë™ì¼)
]

ACCESS_KEY = "minioadmin"
SECRET_KEY = "minioadmin"
LOG_PATH = "s3://model-logs/session-purchase/inference-logs.csv"
OUTPUT_DIR = "ml-pipeline/monitoring/plots"

os.makedirs(OUTPUT_DIR, exist_ok=True)

fs = None
for ep in MINIO_ENDPOINTS:
    try:
        print(f"ğŸ”— Trying MinIO endpoint: {ep}")
        fs = s3fs.S3FileSystem(
            key=ACCESS_KEY,
            secret=SECRET_KEY,
            client_kwargs={"endpoint_url": ep}
        )
        fs.ls("s3://model-logs")
        print(f"âœ… Connected to MinIO at {ep}")
        break
    except Exception as e:
        print(f"âš ï¸ Connection failed ({ep}): {e}")

if fs is None:
    raise RuntimeError("âŒ ëª¨ë“  MinIO endpoint ì—°ê²° ì‹¤íŒ¨. MinIO ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")

# --------------------------------------------------
# 2ï¸âƒ£ ë¡œê·¸ íŒŒì¼ ë¡œë“œ
# --------------------------------------------------
print("ğŸ“¦ Loading inference logs...")
try:
    with fs.open(LOG_PATH, "rb") as f:
        logs = pd.read_csv(f)
    print(f"âœ… Loaded logs â†’ {logs.shape[0]} rows, {logs.shape[1]} columns")
except FileNotFoundError:
    raise FileNotFoundError(f"âŒ ë¡œê·¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {LOG_PATH}")
except Exception as e:
    raise RuntimeError(f"âŒ ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")

# --------------------------------------------------
# 3ï¸âƒ£ ê¸°ë³¸ ì •ë³´
# --------------------------------------------------
print("\n[ğŸ§¾ ë¡œê·¸ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°]")
print(logs.head(3))
print("\n[ğŸ“‹ ë°ì´í„° íƒ€ì… ë° ê²°ì¸¡ì¹˜]")
print(logs.info())
print(logs.isnull().sum())

# --------------------------------------------------
# 4ï¸âƒ£ ê¸°ë³¸ í†µê³„
# --------------------------------------------------
print("\n[ğŸ“Š ê¸°ë³¸ í†µê³„ ìš”ì•½]")
print(logs.describe(include="all"))

# --------------------------------------------------
# 5ï¸âƒ£ ì˜ˆì¸¡ í™•ë¥  ë¶„í¬ ì‹œê°í™” (ì €ì¥)
# --------------------------------------------------
if "probability" in logs.columns:
    plt.figure(figsize=(7, 5))
    sns.histplot(logs["probability"], bins=30, kde=True, color="#6baed6")
    plt.title(" ì˜ˆì¸¡ í™•ë¥  ë¶„í¬", fontsize=13)
    plt.xlabel("ì˜ˆì¸¡ í™•ë¥ ", fontsize=11)
    plt.ylabel("ê°œìˆ˜", fontsize=11)
    plt.grid(True, linestyle="--", alpha=0.6)
    plt.tight_layout()
    save_path = os.path.join(OUTPUT_DIR, "ì˜ˆì¸¡í™•ë¥ _ë¶„í¬.png")
    plt.savefig(save_path, dpi=300, bbox_inches="tight")
    print(f"âœ… ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ â†’ {save_path}")
    plt.close()
else:
    print("âš ï¸ 'probability' ì»¬ëŸ¼ì´ ë¡œê·¸ì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# --------------------------------------------------
# 6ï¸âƒ£ ì˜ˆì¸¡ Label ë¹„ìœ¨ ì‹œê°í™” (ì €ì¥)
# --------------------------------------------------
if "prediction" in logs.columns:
    label_ratio = logs["prediction"].value_counts(normalize=True) * 100
    label_names = {0: "ë¹„êµ¬ë§¤", 1: "êµ¬ë§¤"}
    label_ratio.index = label_ratio.index.map(lambda x: label_names.get(x, str(x)))

    plt.figure(figsize=(5, 5))
    plt.pie(
        label_ratio,
        labels=[f"{i} ({v:.1f}%)" for i, v in label_ratio.items()],
        autopct="%1.1f%%",
        startangle=90,
        colors=["#fd8d3c", "#6baed6"]
    )
    plt.title(" êµ¬ë§¤/ë¹„êµ¬ë§¤ ë¹„ìœ¨", fontsize=13)
    plt.tight_layout()
    save_path = os.path.join(OUTPUT_DIR, "êµ¬ë§¤ë¹„ìœ¨_íŒŒì´ì°¨íŠ¸.png")
    plt.savefig(save_path, dpi=300, bbox_inches="tight")
    print(f"âœ… ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ â†’ {save_path}")
    plt.close()
else:
    print("âš ï¸ 'prediction' ì»¬ëŸ¼ì´ ë¡œê·¸ì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# --------------------------------------------------
# 7ï¸âƒ£ ì‹œê°„ íë¦„ì— ë”°ë¥¸ í™•ë¥  ë³€í™” (ì €ì¥)
# --------------------------------------------------
if "timestamp" in logs.columns and "probability" in logs.columns:
    logs["timestamp"] = pd.to_datetime(logs["timestamp"], errors="coerce")
    logs = logs.dropna(subset=["timestamp"])
    logs = logs.sort_values("timestamp")

    plt.figure(figsize=(10, 4))
    sns.lineplot(x="timestamp", y="probability", data=logs, marker="o", color="#3182bd")
    plt.title(" ì‹œê°„ë³„ ì˜ˆì¸¡ í™•ë¥  ì¶”ì´", fontsize=13)
    plt.xlabel("ì‹œê°„", fontsize=11)
    plt.ylabel("ì˜ˆì¸¡ í™•ë¥ ", fontsize=11)
    plt.grid(True, linestyle="--", alpha=0.6)
    plt.tight_layout()
    save_path = os.path.join(OUTPUT_DIR, "ì‹œê°„ë³„_ì˜ˆì¸¡í™•ë¥ ì¶”ì´.png")
    plt.savefig(save_path, dpi=300, bbox_inches="tight")
    print(f"âœ… ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ â†’ {save_path}")
    plt.close()
else:
    print("âš ï¸ ì‹œê°„ ê¸°ë°˜ ì‹œê°í™”ë¥¼ ìœ„í•œ ì»¬ëŸ¼(timestamp, probability)ì´ ëˆ„ë½ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

# --------------------------------------------------
# 8ï¸âƒ£ ìµœì‹  ë¡œê·¸ 10ê±´
# --------------------------------------------------
print("\n[ğŸ•’ ìµœê·¼ 10ê±´ ë¡œê·¸]")
print(logs.sort_values("timestamp", ascending=False).head(10))

# --------------------------------------------------
# 9ï¸âƒ£ CSV ë°±ì—… ì €ì¥ (ì„ íƒ)
# --------------------------------------------------
backup_path = os.path.join(OUTPUT_DIR, f"inference_logs_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv")
logs.to_csv(backup_path, index=False)
print(f"ğŸ“ ë¡œê·¸ ë°±ì—… ì™„ë£Œ â†’ {backup_path}")

print("\nâœ… ë¡œê·¸ ë¶„ì„ ë° ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ!")
