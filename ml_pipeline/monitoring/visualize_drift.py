# ===============================================================
# ë°ì´í„° ë“œë¦¬í”„íŠ¸ ì‹œê°í™” ìŠ¤í¬ë¦½íŠ¸
# ===============================================================
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import s3fs
import os

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'NanumGothic'
plt.rcParams['axes.unicode_minus'] = False

print("=" * 70)
print("ğŸ“Š ë°ì´í„° ë“œë¦¬í”„íŠ¸ ì‹œê°í™”")
print("=" * 70)

# MinIO ì—°ê²°
fs = s3fs.S3FileSystem(
    key="minioadmin",
    secret="minioadmin",
    client_kwargs={"endpoint_url": "http://localhost:9900"}
)

# ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
OUTPUT_DIR = "ml-pipeline/monitoring/drift_plots"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# --- 1ï¸âƒ£ ë°ì´í„° ë¡œë“œ ---
print("\n[1/3] ë°ì´í„° ë¡œë”©...")

reference_path = "s3://model-logs/session-purchase/reference_data.csv"
log_path = "s3://model-logs/session-purchase/inference-logs.csv"

with fs.open(reference_path, "rb") as f:
    ref_df = pd.read_csv(f)

with fs.open(log_path, "rb") as f:
    cur_df = pd.read_csv(f)

print(f"   âœ… ê¸°ì¤€ ë°ì´í„°: {ref_df.shape[0]:,}í–‰")
print(f"   âœ… í˜„ì¬ ë°ì´í„°: {cur_df.shape[0]}í–‰")

# ê³µí†µ í”¼ì²˜ ì¶”ì¶œ
exclude_cols = ['probability', 'prediction', 'threshold', 'model_version', 
                'used_features', 'timestamp', 'has_transaction']
feature_cols = [col for col in ref_df.columns if col not in exclude_cols]
common_cols = [col for col in cur_df.columns if col in feature_cols]

# í”¼ì²˜ëª… í•œê¸€ ë§¤í•‘
feature_name_map = {
    'cart_depth': 'ì¥ë°”êµ¬ë‹ˆ ë‹´ì€ ìƒí’ˆ ìˆ˜',
    'cart_to_view_ratio': 'ì¥ë°”êµ¬ë‹ˆ ë‹´ê¸° ë¹„ìœ¨',
    'recent_days': 'ë§ˆì§€ë§‰ í™œë™ í›„ ê²½ê³¼ì¼',
    'event_per_session': 'ì„¸ì…˜ ì´ í™œë™ íšŸìˆ˜',
    'total_sessions': 'ì´ ë°©ë¬¸ íšŸìˆ˜',
    'event_diversity': 'í™œë™ ë‹¤ì–‘ì„±',
    'recent_intensity': 'ìµœê·¼ í™œë™ ê°•ë„',
    'recency_ratio': 'ì¬ë°©ë¬¸ ë¹„ìœ¨',
    'session_activity_index': 'í™œë™ ì§€ìˆ˜',
    'frequency': 'í™œë™ ë¹ˆë„'
}

print(f"   ğŸ“‹ ë¶„ì„ í”¼ì²˜: {len(common_cols)}ê°œ")

# --- 2ï¸âƒ£ ë¶„í¬ ë¹„êµ ì‹œê°í™” ---
print("\n[2/3] ë¶„í¬ ë¹„êµ ì‹œê°í™” ìƒì„± ì¤‘...")

# í”¼ì²˜ë‹¹ í•˜ë‚˜ì˜ í”Œë¡¯ ìƒì„±
fig, axes = plt.subplots(len(common_cols), 1, figsize=(12, 4 * len(common_cols)))
if len(common_cols) == 1:
    axes = [axes]

for idx, col in enumerate(common_cols):
    ax = axes[idx]
    
    # ê¸°ì¤€ ë°ì´í„° (ìƒ˜í”Œë§í•˜ì—¬ í¬ê¸° ë§ì¶”ê¸°)
    ref_sample = ref_df[col].sample(min(10000, len(ref_df)), random_state=42)
    
    # íˆìŠ¤í† ê·¸ë¨
    ax.hist(ref_sample, bins=50, alpha=0.5, label='í•™ìŠµ ë°ì´í„°', 
            color='blue', density=True)
    ax.hist(cur_df[col], bins=30, alpha=0.5, label='ìš´ì˜ ë°ì´í„°', 
            color='red', density=True)
    
    # í•œê¸€ í”¼ì²˜ëª… ì‚¬ìš©
    korean_name = feature_name_map.get(col, col)
    ax.set_xlabel(korean_name, fontsize=10)
    ax.set_ylabel('ë°€ë„', fontsize=10)
    ax.set_title(f'ë¶„í¬ ë¹„êµ: {korean_name}', fontsize=12, fontweight='bold')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # í†µê³„ ì •ë³´ ì¶”ê°€
    ref_mean = ref_df[col].mean()
    cur_mean = cur_df[col].mean()
    ref_std = ref_df[col].std()
    cur_std = cur_df[col].std()
    
    stats_text = f'í•™ìŠµ: í‰ê· ={ref_mean:.2f}, í‘œì¤€í¸ì°¨={ref_std:.2f}\n'
    stats_text += f'ìš´ì˜: í‰ê· ={cur_mean:.2f}, í‘œì¤€í¸ì°¨={cur_std:.2f}'
    ax.text(0.98, 0.95, stats_text, transform=ax.transAxes,
            verticalalignment='top', horizontalalignment='right',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),
            fontsize=9)

plt.tight_layout()
save_path = os.path.join(OUTPUT_DIR, "feature_distribution_comparison.png")
plt.savefig(save_path, dpi=300, bbox_inches='tight')
print(f"   âœ… ë¶„í¬ ë¹„êµ ê·¸ë˜í”„ ì €ì¥: {save_path}")
plt.close()

# --- 3ï¸âƒ£ PSI ë¦¬í¬íŠ¸ ì‹œê°í™” ---
print("\n[3/3] PSI ë¦¬í¬íŠ¸ ì‹œê°í™” ì¤‘...")

psi_path = "s3://model-logs/session-purchase/psi_report.csv"
with fs.open(psi_path, "rb") as f:
    psi_df = pd.read_csv(f)

# í”¼ì²˜ëª…ì„ í•œê¸€ë¡œ ë³€ê²½
psi_df['feature_kr'] = psi_df['feature'].map(feature_name_map).fillna(psi_df['feature'])

fig, ax = plt.subplots(figsize=(10, 6))

# PSI ê°’ ë°” ì°¨íŠ¸
colors = psi_df['psi'].apply(
    lambda x: '#27ae60' if x < 0.1 else '#f39c12' if x < 0.25 else '#e74c3c'
)

bars = ax.barh(psi_df['feature_kr'], psi_df['psi'], color=colors)

# ê¸°ì¤€ì„  ì¶”ê°€
ax.axvline(x=0.1, color='green', linestyle='--', linewidth=2, 
           label='ì•ˆì • (< 0.1)', alpha=0.7)
ax.axvline(x=0.25, color='orange', linestyle='--', linewidth=2, 
           label='ë³´í†µ (< 0.25)', alpha=0.7)

ax.set_xlabel('PSI ê°’', fontsize=12, fontweight='bold')
ax.set_ylabel('í”¼ì²˜', fontsize=12, fontweight='bold')
ax.set_title('í”¼ì²˜ë³„ ëª¨ì§‘ë‹¨ ì•ˆì •ì„± ì§€ìˆ˜ (PSI)', 
             fontsize=14, fontweight='bold')
ax.legend(loc='upper right')
ax.grid(True, axis='x', alpha=0.3)

# ê°’ ë ˆì´ë¸” ì¶”ê°€
for i, (feature, psi) in enumerate(zip(psi_df['feature_kr'], psi_df['psi'])):
    ax.text(psi + 0.3, i, f'{psi:.2f}', 
            va='center', fontsize=9, fontweight='bold')

plt.tight_layout()
save_path = os.path.join(OUTPUT_DIR, "psi_report_chart.png")
plt.savefig(save_path, dpi=300, bbox_inches='tight')
print(f"   âœ… PSI ì°¨íŠ¸ ì €ì¥: {save_path}")
plt.close()

# --- 4ï¸âƒ£ í†µê³„ ìš”ì•½ í…Œì´ë¸” ---
print("\nğŸ“ˆ í†µê³„ ìš”ì•½:")
print("=" * 70)

summary_data = []
for col in common_cols:
    summary_data.append({
        'í”¼ì²˜': col,
        'í•™ìŠµ í‰ê· ': f"{ref_df[col].mean():.2f}",
        'ìš´ì˜ í‰ê· ': f"{cur_df[col].mean():.2f}",
        'í•™ìŠµ í‘œì¤€í¸ì°¨': f"{ref_df[col].std():.2f}",
        'ìš´ì˜ í‘œì¤€í¸ì°¨': f"{cur_df[col].std():.2f}",
        'í‰ê·  ì°¨ì´': f"{abs(ref_df[col].mean() - cur_df[col].mean()):.2f}"
    })

summary_df = pd.DataFrame(summary_data)
print(summary_df.to_string(index=False))

print("\n" + "=" * 70)
print("âœ… ì‹œê°í™” ì™„ë£Œ!")
print("=" * 70)
print(f"\nğŸ“‚ ì €ì¥ ìœ„ì¹˜: {OUTPUT_DIR}/")
print("   - feature_distribution_comparison.png")
print("   - psi_report_chart.png")